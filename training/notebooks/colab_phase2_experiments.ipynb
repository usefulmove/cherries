{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: SOTA Optimization Experiments\n",
    "\n",
    "This notebook executes the updated Phase 2 experimental roadmap incorporating external research feedback:\n",
    "\n",
    "**New State-of-the-Art Experiments:**\n",
    "1. **EXP-001**: Threshold Optimization (CPU, 4-6 hours)\n",
    "2. **EXP-002A**: ConvNeXt V2-Tiny Baseline (GPU, ~12 hours) - *FCMAE pre-training*\n",
    "3. **EXP-002B**: ConvNeXt V2-Tiny + Label Smoothing (GPU, ~12 hours)\n",
    "4. **EXP-003A**: EfficientNet-B2 Baseline (GPU, ~10 hours) - *Speed-focused*\n",
    "5. **EXP-003B**: EfficientNet-B2 + Label Smoothing (GPU, ~10 hours)\n",
    "6. **EXP-006A**: DINOv2 ViT-S/14 Linear Probe (GPU, ~4 hours) - *Foundation model*\n",
    "\n",
    "**Key Improvements:**\n",
    "- **Enhanced augmentations**: Motion blur + stronger color jitter for conveyor realism\n",
    "- **ConvNeXt V2**: Upgraded from V1 to V2 with FCMAE pre-training (better for defects)\n",
    "- **DINOv2**: Foundation model approach with frozen backbone + linear probe\n",
    "\n",
    "**Current Baseline:**\n",
    "- ResNet50: 94.05% accuracy, 16ms latency, 25.6M params\n",
    "\n",
    "**Target:**\n",
    "- Accuracy: ≥94.5% (stretch: 95%)\n",
    "- Pit Recall: ≥99.0% (food safety)\n",
    "- Latency: <30ms on CPU\n",
    "\n",
    "**Prerequisites:**\n",
    "- Google Colab Pro (GPU required for training experiments)\n",
    "- Baseline model uploaded to Google Drive\n",
    "- Data in Drive at: `cherry_classification/data/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Experiment Configuration\n",
    "\n",
    "Set skip flags to control which experiments run. Use `SMOKE_TEST=True` for quick validation (1 epoch, 3 batches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXPERIMENT CONFIGURATION ===\n",
    "# Set these flags to control execution\n",
    "\n",
    "SMOKE_TEST = False  # Set True for quick validation (1 epoch, 3 batches)\n",
    "\n",
    "# Skip flags - set True to skip already completed experiments\n",
    "SKIP_EXP_001 = False    # Threshold optimization (CPU only)\n",
    "SKIP_EXP_002A = False   # ConvNeXt V2-Tiny baseline (NEW - Phase 2)\n",
    "SKIP_EXP_002B = False   # ConvNeXt V2-Tiny + label smoothing (NEW)\n",
    "SKIP_EXP_003A = False   # EfficientNet-B2 baseline\n",
    "SKIP_EXP_003B = False   # EfficientNet-B2 + label smoothing\n",
    "SKIP_EXP_006A = False   # DINOv2 ViT-S/14 linear probe (NEW - Phase 2)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Paths (adjust for your Drive structure)\n",
    "DRIVE_MOUNT_PATH = \"/content/drive\"\n",
    "DRIVE_BASE_PATH = \"/content/drive/MyDrive/cherry_experiments\"\n",
    "DATA_PATH = \"/content/cherry_classification/data\"\n",
    "BASELINE_MODEL_PATH = \"/content/drive/MyDrive/cherry_experiments/resnet50_augmented_unnormalized/model_best_fixed.pt\"\n",
    "\n",
    "# Print configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT CONFIGURATION - Phase 2 SOTA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"SMOKE_TEST: {SMOKE_TEST}\")\n",
    "print(f\"RANDOM_SEED: {RANDOM_SEED}\")\n",
    "print(\"\\nPhase 2 NEW Experiments:\")\n",
    "print(f\"  EXP-002A (ConvNeXt V2 baseline): {SKIP_EXP_002A}\")\n",
    "print(f\"  EXP-002B (ConvNeXt V2 + LS): {SKIP_EXP_002B}\")\n",
    "print(f\"  EXP-006A (DINOv2 linear probe): {SKIP_EXP_006A}\")\n",
    "print(\"\\nOther Experiments:\")\n",
    "print(f\"  EXP-001 (Threshold opt): {SKIP_EXP_001}\")\n",
    "print(f\"  EXP-003A (EfficientNet B2): {SKIP_EXP_003A}\")\n",
    "print(f\"  EXP-003B (EfficientNet B2 + LS): {SKIP_EXP_003B}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Environment Setup & Dependencies\n",
    "\n",
    "Install required packages including `timm` for ConvNeXt V2 support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q pyyaml scikit-learn matplotlib tqdm\n",
    "\n",
    "# NEW: Install timm for ConvNeXt V2\n",
    "print(\"Installing timm for ConvNeXt V2...\")\n",
    "!pip install -q timm\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEPENDENCY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check timm\n",
    "try:\n",
    "    import timm\n",
    "    print(f\"✓ timm installed: {timm.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"✗ timm not available - ConvNeXt V2 will fail\")\n",
    "\n",
    "# Check torch\n",
    "import torch\n",
    "print(f\"✓ PyTorch: {torch.__version__}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: GPU Check & Drive Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount(DRIVE_MOUNT_PATH, force_remount=True)\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GPU CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    # Check if we're running training experiments\n",
    "    needs_gpu = not (SKIP_EXP_002A and SKIP_EXP_002B and SKIP_EXP_003A and SKIP_EXP_003B and SKIP_EXP_006A)\n",
    "    \n",
    "    if needs_gpu:\n",
    "        raise RuntimeError(\n",
    "            \"\\n\" + \"!\" * 60 + \"\\n\" +\n",
    "            \"GPU REQUIRED FOR TRAINING EXPERIMENTS!\\n\" +\n",
    "            \"Go to: Runtime -> Change runtime type -> GPU\\n\" +\n",
    "            \"Then re-run this cell.\\n\" +\n",
    "            \"!\" * 60\n",
    "        )\n",
    "    else:\n",
    "        print(\"WARNING: No GPU available, but only running EXP-001 (CPU). Continuing...\")\n",
    "else:\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Clone Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone training repository\n",
    "!if [ ! -d \"/content/traina\" ]; then \\\n",
    "    git clone https://github.com/dedmonds/traina.git /content/traina; \\\n",
    "fi\n",
    "\n",
    "# Clone dataset repository (shallow clone)\n",
    "!if [ ! -d \"/content/cherry_classification\" ]; then \\\n",
    "    git clone --depth 1 https://github.com/weshavener/cherry_classification.git /content/cherry_classification; \\\n",
    "fi\n",
    "\n",
    "# Add training scripts to path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/traina/training')\n",
    "\n",
    "# Create output directories\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "output_dirs = [\n",
    "    f\"{DRIVE_BASE_PATH}/threshold_optimization\",\n",
    "    f\"{DRIVE_BASE_PATH}/convnextv2_tiny_baseline_seed42\",  # NEW: ConvNeXt V2\n",
    "    f\"{DRIVE_BASE_PATH}/convnextv2_tiny_label_smooth_seed42\",\n",
    "    f\"{DRIVE_BASE_PATH}/efficientnet_b2_baseline_seed42\",\n",
    "    f\"{DRIVE_BASE_PATH}/efficientnet_b2_label_smooth_seed42\",\n",
    "    f\"{DRIVE_BASE_PATH}/dinov2_vits14_linear_probe_seed42\",  # NEW: DINOv2\n",
    "]\n",
    "\n",
    "for dir_path in output_dirs:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SETUP COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training code: /content/traina\")\n",
    "print(f\"Data: {DATA_PATH}\")\n",
    "print(f\"Output base: {DRIVE_BASE_PATH}\")\n",
    "\n",
    "# Verify data exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"\\nWARNING: Data not found at {DATA_PATH}\")\n",
    "else:\n",
    "    print(f\"\\nData verified: {DATA_PATH}\")\n",
    "    !ls -lh {DATA_PATH}\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: EXP-001 - Threshold Optimization\n",
    "\n",
    "**Type:** Analysis (no training)\n",
    "**Duration:** 4-6 hours\n",
    "**Requires:** Baseline model (94.05% ResNet50)\n",
    "\n",
    "Find optimal decision boundaries for 3-class classification (clean/pit/maybe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIP_EXP_001:\n",
    "    print(\"EXP-001: SKIPPED (set SKIP_EXP_001=False to run)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RUNNING EXP-001: Threshold Optimization\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Verify baseline model exists\n",
    "    if not os.path.exists(BASELINE_MODEL_PATH):\n",
    "        print(f\"ERROR: Baseline model not found: {BASELINE_MODEL_PATH}\")\n",
    "        print(\"Please upload the 94.05% ResNet50 model to Google Drive\")\n",
    "        print(\"Expected location: MyDrive/cherry_experiments/resnet50_augmented_unnormalized/model_best_fixed.pt\")\n",
    "    else:\n",
    "        output_dir = f\"{DRIVE_BASE_PATH}/threshold_optimization\"\n",
    "        \n",
    "        # Run threshold optimization\n",
    "        !python /content/traina/training/scripts/optimize_thresholds.py \\\n",
    "            --model-path {BASELINE_MODEL_PATH} \\\n",
    "            --data-root {DATA_PATH} \\\n",
    "            --architecture resnet50 \\\n",
    "            --output-dir {output_dir} \\\n",
    "            --min-recall 0.99 \\\n",
    "            --device cpu\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Results saved to: {output_dir}\")\n",
    "        print(\"\\nKey files to download:\")\n",
    "        print(\"  - threshold_results.json\")\n",
    "        print(\"  - optimal_thresholds.yaml\")\n",
    "        print(\"  - threshold_analysis.png\")\n",
    "        print(\"  - probability_distributions.png\")\n",
    "        print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: EXP-002A - ConvNeXt V2-Tiny Baseline (NEW - Phase 2)\n",
    "\n",
    "**Type:** Training\n",
    "**Duration:** ~12 hours (30 epochs)\n",
    "**Architecture:** ConvNeXt V2-Tiny with FCMAE pre-training (via timm)\n",
    "**Key Feature:** Enhanced augmentations with motion blur for conveyor realism\n",
    "**Hypothesis:** FCMAE pre-training superior for defect detection, ≥94.5% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIP_EXP_002A:\n",
    "    print(\"EXP-002A: SKIPPED (set SKIP_EXP_002A=False to run)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RUNNING EXP-002A: ConvNeXt V2-Tiny Baseline (Phase 2)\")\n",
    "    print(\"Features: FCMAE pre-training, AdamW optimizer, enhanced augmentations\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set random seed\n",
    "    import random\n",
    "    import numpy as np\n",
    "    \n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    \n",
    "    print(f\"Random seed set: {RANDOM_SEED}\")\n",
    "    \n",
    "    # Load config\n",
    "    import yaml\n",
    "    \n",
    "    config_path = \"/content/traina/training/configs/experiments/convnextv2_tiny_baseline_seed42.yaml\"\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Override paths for Colab\n",
    "    config['checkpointing']['output_dir'] = f\"{DRIVE_BASE_PATH}/convnextv2_tiny_baseline_seed42\"\n",
    "    config['data']['root'] = DATA_PATH\n",
    "    \n",
    "    # Apply smoke test settings\n",
    "    if SMOKE_TEST:\n",
    "        print(\"\\nSMOKE TEST MODE: 1 epoch, 3 batches\")\n",
    "        config['training']['epochs'] = 1\n",
    "        config['checkpointing']['save_every'] = 1\n",
    "    \n",
    "    # Save temp config\n",
    "    temp_config = \"/tmp/convnextv2_tiny_baseline_seed42.yaml\"\n",
    "    with open(temp_config, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "    \n",
    "    # Run training\n",
    "    !python /content/traina/training/scripts/train.py \\\n",
    "        --config {temp_config} \\\n",
    "        --data-root {DATA_PATH}\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Training complete! Results: {config['checkpointing']['output_dir']}\")\n",
    "    print(\"\\nKey files to download:\")\n",
    "    print(\"  - model_best.pt\")\n",
    "    print(\"  - metrics.json\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: EXP-002B - ConvNeXt V2-Tiny with Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIP_EXP_002B:\n",
    "    print(\"EXP-002B: SKIPPED (set SKIP_EXP_002B=False to run)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RUNNING EXP-002B: ConvNeXt V2-Tiny with Label Smoothing\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set random seed\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    \n",
    "    print(f\"Random seed set: {RANDOM_SEED}\")\n",
    "    print(\"Label smoothing: alpha=0.1\")\n",
    "    \n",
    "    # Load config\n",
    "    config_path = \"/content/traina/training/configs/experiments/convnextv2_tiny_label_smooth_seed42.yaml\"\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Override paths\n",
    "    config['checkpointing']['output_dir'] = f\"{DRIVE_BASE_PATH}/convnextv2_tiny_label_smooth_seed42\"\n",
    "    config['data']['root'] = DATA_PATH\n",
    "    \n",
    "    # Apply smoke test settings\n",
    "    if SMOKE_TEST:\n",
    "        print(\"\\nSMOKE TEST MODE: 1 epoch, 3 batches\")\n",
    "        config['training']['epochs'] = 1\n",
    "        config['checkpointing']['save_every'] = 1\n",
    "    \n",
    "    # Save temp config\n",
    "    temp_config = \"/tmp/convnextv2_tiny_label_smooth_seed42.yaml\"\n",
    "    with open(temp_config, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "    \n",
    "    # Run training\n",
    "    !python /content/traina/training/scripts/train.py \\\n",
    "        --config {temp_config} \\\n",
    "        --data-root {DATA_PATH}\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Training complete! Results: {config['checkpointing']['output_dir']}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: EXP-003A - EfficientNet-B2 Baseline\n",
    "\n",
    "**Type:** Training\n",
    "**Duration:** ~10 hours\n",
    "**Architecture:** EfficientNet-B2 (9.2M params)\n",
    "**Key Feature:** Speed-focused alternative, unnormalized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIP_EXP_003A:\n",
    "    print(\"EXP-003A: SKIPPED (set SKIP_EXP_003A=False to run)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RUNNING EXP-003A: EfficientNet-B2 Baseline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set random seed\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    \n",
    "    print(f\"Random seed set: {RANDOM_SEED}\")\n",
    "    \n",
    "    # Load config\n",
    "    config_path = \"/content/traina/training/configs/experiments/efficientnet_b2_baseline_seed42.yaml\"\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Override paths\n",
    "    config['checkpointing']['output_dir'] = f\"{DRIVE_BASE_PATH}/efficientnet_b2_baseline_seed42\"\n",
    "    config['data']['root'] = DATA_PATH\n",
    "    \n",
    "    # Apply smoke test settings\n",
    "    if SMOKE_TEST:\n",
    "        print(\"\\nSMOKE TEST MODE: 1 epoch, 3 batches\")\n",
    "        config['training']['epochs'] = 1\n",
    "        config['checkpointing']['save_every'] = 1\n",
    "    \n",
    "    # Save temp config\n",
    "    temp_config = \"/tmp/efficientnet_b2_baseline_seed42.yaml\"\n",
    "    with open(temp_config, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "    \n",
    "    # Run training\n",
    "    !python /content/traina/training/scripts/train.py \\\n",
    "        --config {temp_config} \\\n",
    "        --data-root {DATA_PATH}\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Training complete! Results: {config['checkpointing']['output_dir']}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: EXP-003B - EfficientNet-B2 with Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIP_EXP_003B:\n",
    "    print(\"EXP-003B: SKIPPED (set SKIP_EXP_003B=False to run)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RUNNING EXP-003B: EfficientNet-B2 with Label Smoothing\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set random seed\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    \n",
    "    print(f\"Random seed set: {RANDOM_SEED}\")\n",
    "    print(\"Label smoothing: alpha=0.1\")\n",
    "    \n",
    "    # Load config\n",
    "    config_path = \"/content/traina/training/configs/experiments/efficientnet_b2_label_smooth_seed42.yaml\"\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Override paths\n",
    "    config['checkpointing']['output_dir'] = f\"{DRIVE_BASE_PATH}/efficientnet_b2_label_smooth_seed42\"\n",
    "    config['data']['root'] = DATA_PATH\n",
    "    \n",
    "    # Apply smoke test settings\n",
    "    if SMOKE_TEST:\n",
    "        print(\"\\nSMOKE TEST MODE: 1 epoch, 3 batches\")\n",
    "        config['training']['epochs'] = 1\n",
    "        config['checkpointing']['save_every'] = 1\n",
    "    \n",
    "    # Save temp config\n",
    "    temp_config = \"/tmp/efficientnet_b2_label_smooth_seed42.yaml\"\n",
    "    with open(temp_config, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "    \n",
    "    # Run training\n",
    "    !python /content/traina/training/scripts/train.py \\\n",
    "        --config {temp_config} \\\n",
    "        --data-root {DATA_PATH}\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Training complete! Results: {config['checkpointing']['output_dir']}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: EXP-006A - DINOv2 ViT-S/14 Linear Probe (NEW - Phase 2)\n",
    "\n",
    "**Type:** Training (frozen backbone)\n",
    "**Duration:** ~4-6 hours (fast training - only linear head optimized)\n",
    "**Architecture:** DINOv2 ViT-S/14 foundation model\n",
    "**Key Feature:** Self-supervised features, frozen backbone + trainable head\n",
    "**Hypothesis:** Foundation model features will achieve ≥94.5% with minimal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIP_EXP_006A:\n",
    "    print(\"EXP-006A: SKIPPED (set SKIP_EXP_006A=False to run)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RUNNING EXP-006A: DINOv2 ViT-S/14 Linear Probe (Phase 2)\")\n",
    "    print(\"Features: Frozen foundation backbone, fast training, normalized input\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set random seed\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    \n",
    "    print(f\"Random seed set: {RANDOM_SEED}\")\n",
    "    \n",
    "    # Load config\n",
    "    config_path = \"/content/traina/training/configs/experiments/dinov2_vits14_linear_probe_seed42.yaml\"\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Override paths\n",
    "    config['checkpointing']['output_dir'] = f\"{DRIVE_BASE_PATH}/dinov2_vits14_linear_probe_seed42\"\n",
    "    config['data']['root'] = DATA_PATH\n",
    "    \n",
    "    # Apply smoke test settings\n",
    "    if SMOKE_TEST:\n",
    "        print(\"\\nSMOKE TEST MODE: 1 epoch, 3 batches\")\n",
    "        config['training']['epochs'] = 1\n",
    "        config['checkpointing']['save_every'] = 1\n",
    "    \n",
    "    # Save temp config\n",
    "    temp_config = \"/tmp/dinov2_vits14_linear_probe_seed42.yaml\"\n",
    "    with open(temp_config, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "    \n",
    "    # Run training\n",
    "    !python /content/traina/training/scripts/train.py \\\n",
    "        --config {temp_config} \\\n",
    "        --data-root {DATA_PATH}\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Training complete! Results: {config['checkpointing']['output_dir']}\")\n",
    "    print(\"\\nNOTE: DINOv2 inference may be slower than CNNs. If accurate but slow,\")\n",
    "    print(\"      consider using it as a teacher for distillation.\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Experiment Summary\n",
    "\n",
    "View all completed experiments and their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT SUMMARY - Phase 2 SOTA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(DRIVE_BASE_PATH)\n",
    "\n",
    "print(\"\\nCompleted Experiments:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Check each experiment directory\n",
    "for exp_dir in sorted(base_path.glob(\"*\")):\n",
    "    if exp_dir.is_dir():\n",
    "        metrics_file = exp_dir / \"metrics.json\"\n",
    "        model_file = exp_dir / \"model_best.pt\"\n",
    "        \n",
    "        if metrics_file.exists():\n",
    "            # Read last line for final metrics\n",
    "            with open(metrics_file) as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    try:\n",
    "                        last_entry = json.loads(lines[-1])\n",
    "                        acc = last_entry.get('accuracy', 'N/A')\n",
    "                        epoch = last_entry.get('epoch', 'N/A')\n",
    "                        phase = last_entry.get('phase', 'N/A')\n",
    "                        \n",
    "                        if phase == 'val':\n",
    "                            status = '✓' if model_file.exists() else '⚠'\n",
    "                            print(f\"{status} {exp_dir.name:45s} | Epoch {epoch:2s} | Acc: {acc}\")\n",
    "                            results.append({\n",
    "                                'name': exp_dir.name,\n",
    "                                'accuracy': acc,\n",
    "                                'epoch': epoch\n",
    "                            })\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if results:\n",
    "    print(f\"\\nTotal experiments completed: {len(results)}\")\n",
    "    \n",
    "    # Find best accuracy\n",
    "    valid_results = [r for r in results if isinstance(r['accuracy'], (int, float))]\n",
    "    if valid_results:\n",
    "        best = max(valid_results, key=lambda x: x['accuracy'])\n",
    "        print(f\"\\nBest model: {best['name']}\")\n",
    "        print(f\"Accuracy: {best['accuracy']:.2%}\")\n",
    "        \n",
    "        # Identify Phase 2 experiments\n",
    "        phase2_models = [r for r in valid_results if 'convnextv2' in r['name'] or 'dinov2' in r['name']]\n",
    "        if phase2_models:\n",
    "            best_p2 = max(phase2_models, key=lambda x: x['accuracy'])\n",
    "            print(f\"\\nBest Phase 2 (SOTA) model: {best_p2['name']}\")\n",
    "            print(f\"Accuracy: {best_p2['accuracy']:.2%}\")\n",
    "else:\n",
    "    print(\"\\nNo completed experiments found yet.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"All results saved to: {DRIVE_BASE_PATH}\")\n",
    "print(\"\\nDownload these files for local analysis:\")\n",
    "print(\"  - model_best.pt (trained model weights)\")\n",
    "print(\"  - metrics.json (training history)\")\n",
    "print(\"  - config.yaml (experiment configuration)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Model Comparison & Decision Matrix\n",
    "\n",
    "Compare all trained models and make deployment decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON & DECISION MATRIX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find all model_best.pt files\n",
    "model_files = list(Path(DRIVE_BASE_PATH).rglob(\"model_best.pt\"))\n",
    "\n",
    "print(f\"\\nFound {len(model_files)} trained model(s)\")\n",
    "\n",
    "if len(model_files) >= 1:\n",
    "    print(\"\\nModels available:\")\n",
    "    for i, model_path in enumerate(model_files, 1):\n",
    "        exp_name = model_path.parent.name\n",
    "        is_phase2 = 'convnextv2' in exp_name or 'dinov2' in exp_name\n",
    "        marker = \" [Phase 2 SOTA]\" if is_phase2 else \"\"\n",
    "        print(f\"  {i}. {exp_name}{marker}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DECISION CRITERIA:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Deploy if:\")\n",
    "    print(\"  ✓ Accuracy ≥ 94.05% (beats baseline)\")\n",
    "    print(\"  ✓ Latency < 30ms on CPU\")\n",
    "    print(\"  ✓ Pit recall ≥ 99.0% (food safety)\")\n",
    "    print(\"\\nPhase 2 Priority:\")\n",
    "    print(\"  1. ConvNeXt V2-Tiny (best accuracy/speed tradeoff)\")\n",
    "    print(\"  2. DINOv2 (if accuracy > 95%, consider distillation)\")\n",
    "    print(\"  3. EfficientNet-B2 (if speed is critical)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Next steps after training:\")\n",
    "    print(\"  1. Run local comparison: python scripts/compare_models.py\")\n",
    "    print(\"  2. Benchmark latency on production hardware\")\n",
    "    print(\"  3. Optimize thresholds for 3-class deployment\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Download Results\n",
    "\n",
    "Create download script for transferring results from Drive to local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create download script\n",
    "download_script = f\"\"\"\n",
    "#!/bin/bash\n",
    "# Download Phase 2 experiment results from Google Drive\n",
    "\n",
    "# Source (Google Drive path)\n",
    "DRIVE_SOURCE=\"{DRIVE_BASE_PATH}\"\n",
    "\n",
    "# Destination (local path)\n",
    "LOCAL_DEST=\"./training/experiments\"\n",
    "\n",
    "echo \"Downloading Phase 2 experiment results...\"\n",
    "echo \"From: $DRIVE_SOURCE\"\n",
    "echo \"To: $LOCAL_DEST\"\n",
    "\n",
    "# Create destination directory\n",
    "mkdir -p $LOCAL_DEST\n",
    "\n",
    "# Sync from Drive\n",
    "rsync -av --progress \"$DRIVE_SOURCE/\" \"$LOCAL_DEST/\"\n",
    "\n",
    "echo \"Download complete!\"\n",
    "echo \"\\nPhase 2 models to evaluate:\"\n",
    "ls -lh $LOCAL_DEST/*/model_best.pt 2>/dev/null || echo \"No models found\"\n",
    "\"\"\"\n",
    "\n",
    "# Save script\n",
    "script_path = f\"{DRIVE_BASE_PATH}/download_phase2_results.sh\"\n",
    "with open(script_path, 'w') as f:\n",
    "    f.write(download_script)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOWNLOAD INSTRUCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Download script created: {script_path}\")\n",
    "print(\"\\nTo download results to your local machine:\")\n",
    "print(\"1. Open a terminal on your local machine\")\n",
    "print(\"2. Navigate to your project root\")\n",
    "print(\"3. Run the download script:\")\n",
    "print(f\"\\n   bash {script_path}\")\n",
    "print(\"\\nOr manually copy from Google Drive:\")\n",
    "print(f\"   Source: {DRIVE_BASE_PATH}\")\n",
    "print(\"   Dest: ./training/experiments/\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This Phase 2 notebook implements state-of-the-art approaches based on external research:\n",
    "\n",
    "### What's New\n",
    "1. **ConvNeXt V2** - FCMAE pre-training for superior defect detection\n",
    "2. **DINOv2** - Foundation model with linear probe (fast training, high accuracy)\n",
    "3. **Enhanced Augmentations** - Motion blur + photometric distortion for conveyor realism\n",
    "\n",
    "### Experiment Priority\n",
    "1. **EXP-001** - Run first (CPU, immediate value)\n",
    "2. **EXP-006A** - DINOv2 (fast, high potential)\n",
    "3. **EXP-002A/B** - ConvNeXt V2 (main contender)\n",
    "4. **EXP-003A/B** - EfficientNet (speed alternative)\n",
    "\n",
    "### Success Criteria\n",
    "- **Minimum:** ≥94.05% accuracy (beat baseline)\n",
    "- **Target:** ≥94.5% accuracy\n",
    "- **Stretch:** ≥95% accuracy or <10ms latency\n",
    "\n",
    "### References\n",
    "- [Experiment Specifications](../../docs/reference/EXPERIMENT_SPECIFICATIONS.md)\n",
    "- [Phase 2 Implementation Summary](../../docs/reference/PHASE2_IMPLEMENTATION_SUMMARY.md)\n",
    "- External Research: temp-external-research/claude.md, gemini.md, gpt.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

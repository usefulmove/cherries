{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Stage Robust Training: Field Variation Hardening\n",
    "\n",
    "This notebook implements a **2-Pass Training Workflow** designed to improve robustness against field variation (lighting, motion blur, orientation) which is currently causing a gap between validation accuracy and production performance.\n",
    "\n",
    "## The Strategy\n",
    "\n",
    "1.  **Robust Architectures**: Uses **ConvNeXt V2** (Masked Autoencoder pre-training) or **DINOv2** (Self-supervised) for superior feature robustness.\n",
    "2.  **Field Simulator Augmentation**: Aggressive Motion Blur, Color Jitter, and Affine transforms to simulate production conditions.\n",
    "3.  **Hard Example Mining (2-Pass)**:\n",
    "    *   **Stage 1**: Train a standard Binary Classifier (Clean vs Pit).\n",
    "    *   **Mining**: Run inference on the training set to find \"ambiguous\" or \"confidently wrong\" examples.\n",
    "    *   **Stage 2**: Relabel these as `maybe` and fine-tune a 3-class model (Clean/Maybe/Pit).\n",
    "\n",
    "## Prerequisites\n",
    "- Google Colab Pro (GPU required)\n",
    "- Data in Google Drive: `cherry_classification/data/train` (clean/pit folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q timm albumentations matplotlib scikit-learn\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Set Random Seed\n",
    "SEED = 42\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === USER CONFIGURATION ===\n",
    "\n",
    "# Model Selection\n",
    "# Options: \"convnextv2_tiny\", \"resnet50\", \"dinov2_vits14\"\n",
    "MODEL_ARCH = \"convnextv2_tiny\" \n",
    "\n",
    "# Training Params\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_STAGE1 = 15\n",
    "EPOCHS_STAGE2 = 15\n",
    "LR = 1e-4\n",
    "WD = 1e-4\n",
    "\n",
    "# Mining Thresholds\n",
    "# If probability of pit is between these values, mark as 'maybe'\n",
    "MAYBE_MIN = 0.35 \n",
    "MAYBE_MAX = 0.65\n",
    "\n",
    "# Robustness Params\n",
    "AUGMENT_LEVEL = \"heavy\" # \"standard\" or \"heavy\"\n",
    "\n",
    "# Paths\n",
    "DRIVE_ROOT = Path(\"/content/drive/MyDrive/cherry_experiments/2stage_robust\")\n",
    "DATA_SOURCE = Path(\"/content/cherry_classification/data\")\n",
    "DATA_STAGE1 = Path(\"/content/data_stage1\")\n",
    "DATA_STAGE2 = Path(\"/content/data_stage2\")\n",
    "\n",
    "# Setup output directory\n",
    "DRIVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Results will be saved to: {DRIVE_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation & Augmentation (Field Simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Data if needed\n",
    "if not DATA_SOURCE.exists():\n",
    "    print(\"Cloning dataset...\")\n",
    "    !git clone --depth 1 https://github.com/weshavener/cherry_classification.git /content/cherry_classification\n",
    "\n",
    "# Prepare Stage 1 Data (Copy to local VM for speed)\n",
    "if DATA_STAGE1.exists(): shutil.rmtree(DATA_STAGE1)\n",
    "shutil.copytree(DATA_SOURCE / \"train\", DATA_STAGE1 / \"train\")\n",
    "shutil.copytree(DATA_SOURCE / \"val\", DATA_STAGE1 / \"val\")\n",
    "print(\"Stage 1 Data Ready.\")\n",
    "\n",
    "# --- Augmentations ---\n",
    "def get_transforms(mode=\"train\", level=\"standard\"):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Note: Production model inputs are often unnormalized (0-255).\n",
    "    # However, pre-trained models (timm) usually expect normalization.\n",
    "    # We will use normalization here for stability, but remember to normalize in inference.\n",
    "    \n",
    "    if mode == \"val\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "        \n",
    "    # Train Augmentations\n",
    "    aug_list = [\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "    ]\n",
    "    \n",
    "    if level == \"heavy\":\n",
    "        aug_list.extend([\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.05), # Strobe simulation\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)), # Motion blur simulation\n",
    "        ])\n",
    "    \n",
    "    aug_list.append(transforms.ToTensor())\n",
    "    aug_list.append(normalize)\n",
    "    \n",
    "    return transforms.Compose(aug_list)\n",
    "\n",
    "# --- Data Loaders ---\n",
    "def create_loader(data_dir, batch_size, mode=\"train\", weighted=True):\n",
    "    dataset = datasets.ImageFolder(\n",
    "        data_dir, \n",
    "        transform=get_transforms(mode, level=AUGMENT_LEVEL)\n",
    "    )\n",
    "    \n",
    "    sampler = None\n",
    "    if weighted and mode == \"train\":\n",
    "        targets = dataset.targets\n",
    "        class_counts = np.bincount(targets)\n",
    "        class_weights = 1. / class_counts\n",
    "        sample_weights = class_weights[targets]\n",
    "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "        shuffle = False\n",
    "    else:\n",
    "        shuffle = (mode == \"train\")\n",
    "        \n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, sampler=sampler, num_workers=2)\n",
    "\n",
    "train_loader_s1 = create_loader(DATA_STAGE1 / \"train\", BATCH_SIZE, \"train\")\n",
    "val_loader_s1 = create_loader(DATA_STAGE1 / \"val\", BATCH_SIZE, \"val\", weighted=False)\n",
    "\n",
    "print(f\"Classes Stage 1: {train_loader_s1.dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(arch, num_classes):\n",
    "    print(f\"Creating {arch} for {num_classes} classes...\")\n",
    "    \n",
    "    if arch == \"convnextv2_tiny\":\n",
    "        model = timm.create_model('convnextv2_tiny.fcmae_ft_in1k', pretrained=True, num_classes=num_classes)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "    elif arch == \"dinov2_vits14\":\n",
    "        model = timm.create_model('vit_small_patch14_dinov2.lvd142m', pretrained=True, num_classes=num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {arch}\")\n",
    "        \n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs, save_path):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}, Val Acc = {acc:.2%}\")\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"--> New Best Model Saved: {save_path}\")\n",
    "            \n",
    "    print(f\"Training Complete. Best Accuracy: {best_acc:.2%}\")\n",
    "    \n",
    "    # Load best weights\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stage 1: Binary Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STARTING STAGE 1 (BINARY) ===\")\n",
    "model_s1 = create_model(MODEL_ARCH, num_classes=2)\n",
    "save_path_s1 = DRIVE_ROOT / \"stage1_best.pt\"\n",
    "\n",
    "model_s1 = train_model(\n",
    "    model_s1, \n",
    "    train_loader_s1, \n",
    "    val_loader_s1, \n",
    "    epochs=EPOCHS_STAGE1, \n",
    "    save_path=save_path_s1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hard Example Mining (The \"Maybe\" Creator)\n",
    "\n",
    "We now run the Stage 1 model over **both** the training and validation sets.\n",
    "Images that are misclassified OR have low confidence ($0.35 < p < 0.65$) are moved to the `maybe` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MINING HARD EXAMPLES ===\")\n",
    "\n",
    "def mine_data(source_dir, dest_dir, mode=\"train\"):\n",
    "    print(f\"Mining {mode} set: {source_dir} -> {dest_dir}\")\n",
    "    \n",
    "    # Create inference dataset (No Augmentation)\n",
    "    dataset_mine = datasets.ImageFolder(\n",
    "        source_dir, \n",
    "        transform=get_transforms(\"val\")\n",
    "    )\n",
    "    loader_mine = DataLoader(dataset_mine, batch_size=1, shuffle=False)\n",
    "    \n",
    "    model_s1.eval()\n",
    "    moves = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Prepare destination folder for 'maybe'\n",
    "    maybe_dest = dest_dir / \"maybe\"\n",
    "    maybe_dest.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Prepare other class folders in dest\n",
    "    for cls in dataset_mine.classes:\n",
    "        (dest_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(tqdm(loader_mine, desc=f\"Mining {mode}\")):\n",
    "            img = img.to(device)\n",
    "            output = model_s1(img)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(probs, dim=1).item()\n",
    "            conf = probs.max().item()\n",
    "            pit_prob = probs[0][1].item() # Probability of being a pit\n",
    "            \n",
    "            is_wrong = (pred != label.item())\n",
    "            is_ambiguous = (MAYBE_MIN < pit_prob < MAYBE_MAX)\n",
    "            \n",
    "            # Get source path\n",
    "            src_path, _ = dataset_mine.samples[i]\n",
    "            filename = Path(src_path).name\n",
    "            src_cls = dataset_mine.classes[label.item()]\n",
    "            \n",
    "            if is_wrong or is_ambiguous:\n",
    "                # Move to 'maybe'\n",
    "                dest_path = maybe_dest / filename\n",
    "                moves += 1\n",
    "            else:\n",
    "                # Move to original class folder\n",
    "                dest_path = dest_dir / src_cls / filename\n",
    "            \n",
    "            # Copy file (safer than move, preserves original just in case)\n",
    "            shutil.copy2(src_path, dest_path)\n",
    "            total += 1\n",
    "            \n",
    "    print(f\"  -> Moved {moves}/{total} ({moves/total:.1%}) images to 'maybe' class.\")\n",
    "    \n",
    "    # Safety check: if 'maybe' is empty, delete it to prevent ImageFolder crash\n",
    "    if len(list(maybe_dest.glob(\"*\"))) == 0:\n",
    "        print(f\"  WARNING: No 'maybe' samples found in {mode} set! Removing empty folder.\")\n",
    "        maybe_dest.rmdir()\n",
    "\n",
    "# 1. Setup Stage 2 Directory Structure (Clean Slate)\n",
    "if DATA_STAGE2.exists(): shutil.rmtree(DATA_STAGE2)\n",
    "DATA_STAGE2.mkdir(parents=True)\n",
    "\n",
    "# 2. Run Mining on TRAIN and VAL\n",
    "mine_data(DATA_STAGE1 / \"train\", DATA_STAGE2 / \"train\", mode=\"train\")\n",
    "mine_data(DATA_STAGE1 / \"val\", DATA_STAGE2 / \"val\", mode=\"val\")\n",
    "\n",
    "print(\"Mining Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Stage 2: 3-Class Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STARTING STAGE 2 (3-CLASS) ===\")\n",
    "\n",
    "# Create Loaders for Stage 2\n",
    "# This will now safely load 'maybe' class if it exists (or just clean/pit if empty)\n",
    "train_loader_s2 = create_loader(DATA_STAGE2 / \"train\", BATCH_SIZE, \"train\")\n",
    "val_loader_s2 = create_loader(DATA_STAGE2 / \"val\", BATCH_SIZE, \"val\", weighted=False)\n",
    "\n",
    "print(f\"Classes Stage 2 (Train): {train_loader_s2.dataset.classes}\")\n",
    "print(f\"Classes Stage 2 (Val):   {val_loader_s2.dataset.classes}\")\n",
    "\n",
    "# Modify Model Head\n",
    "num_classes_s2 = len(train_loader_s2.dataset.classes)\n",
    "print(f\"Adapting model head for {num_classes_s2} classes...\")\n",
    "\n",
    "num_features = model_s1.get_classifier().in_features\n",
    "model_s1.reset_classifier(num_classes=num_classes_s2)\n",
    "model_s2 = model_s1.to(device)\n",
    "\n",
    "save_path_s2 = DRIVE_ROOT / \"stage2_best_3class.pt\"\n",
    "\n",
    "# Train\n",
    "model_s2 = train_model(\n",
    "    model_s2, \n",
    "    train_loader_s2, \n",
    "    val_loader_s2, \n",
    "    epochs=EPOCHS_STAGE2, \n",
    "    save_path=save_path_s2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "print(\"Evaluating Final Model on Validation Set...\")\n",
    "model_s2.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader_s2:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model_s2(imgs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=val_loader_s2.dataset.classes))\n",
    "\n",
    "print(\"\\nDone! Model saved to Google Drive.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
